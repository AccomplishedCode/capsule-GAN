{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Lambda, Layer\n",
    "from capsulelayers import CapsuleLayer, PrimaryCap, Length, Mask\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import initializers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# The length of the output vector of a capsule is to represent the probability that the entity represented by the capsule\n",
    "# is present in the current unit. A nonlinear squashing function ensures that\n",
    "# - short vectors get shrunk to almost zero length and\n",
    "# - long vectors get shrunk to a length slightly below 1\n",
    "# this function is designed as\n",
    "# v_j = \\frac{||s_j||^2}{1 + ||s_j||^2 } \\frac{s_j}{||s_j||}\n",
    "#\n",
    "def squash(output_vector, axis=-1):\n",
    "    norm = tf.reduce_sum(tf.square(output_vector), axis, keep_dims=True)\n",
    "    return output_vector * norm / ((1 + norm) * tf.sqrt(norm + 1.0e-10))\n",
    "\n",
    "#\n",
    "# This layer takes to input vectors:\n",
    "#   - the first one is the output of the CapsuleLayer, 'n_calss' arrays\n",
    "#   - the ground truth vector, an array with a length of 'n_class', with one of the elements is '1', the rests are '0'\n",
    "#\n",
    "class MaskingLayer(Layer):\n",
    "    def call(self, inputs, **kwargs):\n",
    "        input, mask = inputs\n",
    "        return K.batch_dot(input, mask, 1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        *_, output_shape = input_shape[0]\n",
    "        return (None, output_shape)\n",
    "\n",
    "\n",
    "#\n",
    "# construct a conv layer, then reshape and apply squash operation\n",
    "#\n",
    "def PrimaryCapsule(n_vector, n_channel, n_kernel_size, n_stride, padding='valid'):\n",
    "    def builder(inputs):\n",
    "        output = Conv2D(filters=n_vector * n_channel, kernel_size=n_kernel_size, strides=n_stride, padding=padding)(inputs)\n",
    "        output = Reshape( target_shape=[-1, n_vector], name='primary_capsule_reshape')(output)\n",
    "        return Lambda(squash, name='primary_capsule_squash')(output)\n",
    "    return builder\n",
    "\n",
    "#\n",
    "# Traditional Neural Network          Capsule\n",
    "# scalar in scalar out       -->>     vector in vector out/matrix in matrix out\n",
    "# back propagation update    -->>     routing update\n",
    "#\n",
    "class CapsuleLayer(Layer):\n",
    "    def __init__(self, n_capsule, n_vec, n_routing, **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.n_capsule = n_capsule\n",
    "        self.n_vector = n_vec\n",
    "        self.n_routing = n_routing\n",
    "        self.kernel_initializer = initializers.get('he_normal')\n",
    "        self.bias_initializer = initializers.get('zeros')\n",
    "\n",
    "    def build(self, input_shape): # input_shape is a 4D tensor\n",
    "        _, self.input_n_capsule, self.input_n_vector, *_ = input_shape\n",
    "        self.W = self.add_weight(shape=[self.input_n_capsule, self.n_capsule, self.input_n_vector, self.n_vector], initializer=self.kernel_initializer, name='W')\n",
    "        self.bias = self.add_weight(shape=[1, self.input_n_capsule, self.n_capsule, 1, 1], initializer=self.bias_initializer, name='bias', trainable=False)\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        input_expand = tf.expand_dims(tf.expand_dims(inputs, 2), 2)\n",
    "        input_tiled = tf.tile(input_expand, [1, 1, self.n_capsule, 1, 1])\n",
    "        input_hat = tf.scan(lambda ac, x: K.batch_dot(x, self.W, [3, 2]), elems=input_tiled, initializer=K.zeros( [self.input_n_capsule, self.n_capsule, 1, self.n_vector]))\n",
    "        for i in range(self.n_routing): # routing\n",
    "            c = tf.nn.softmax(self.bias, dim=2)\n",
    "            outputs = squash(tf.reduce_sum( c * input_hat, axis=1, keep_dims=True))\n",
    "            if i != self.n_routing - 1:\n",
    "                self.bias += tf.reduce_sum(input_hat * outputs, axis=-1, keep_dims=True)\n",
    "        return tf.reshape(outputs, [-1, self.n_capsule, self.n_vector])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # output current layer capsules\n",
    "        return (None, self.n_capsule, self.n_vector)\n",
    "\n",
    "#\n",
    "# This layer takes 'n_class' arrays as input, outputs an array of size 'n_class',\n",
    "# each eleemnt in the output array represent the possibility,\n",
    "# i.e., the last layer in Figure 2.\n",
    "#\n",
    "class LengthLayer(Layer):\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return tf.sqrt(tf.reduce_sum(tf.square(inputs), axis=-1, keep_dims=False))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        *output_shape, _ = input_shape\n",
    "        return tuple(output_shape)\n",
    "    \n",
    "    \n",
    "#\n",
    "# margin loss is employed to measure the accuracy of the capsule net,\n",
    "# in the code below, mean absolute error is used to measure the accuracy of the reconstructed image\n",
    "#\n",
    "def margin_loss(y_ground_truth, y_prediction):\n",
    "    _m_plus = 0.9\n",
    "    _m_minus = 0.1\n",
    "    _lambda = 0.5\n",
    "    L = y_ground_truth * tf.square(tf.maximum(0., _m_plus - y_prediction)) + _lambda * ( 1 - y_ground_truth) * tf.square(tf.maximum(0., y_prediction - _m_minus))\n",
    "    return tf.reduce_mean(tf.reduce_sum(L, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 28 \n",
    "img_cols = 28\n",
    "channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(0.0002, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "\n",
    "    noise_shape = (100,)\n",
    "    x_noise = Input(shape=noise_shape)\n",
    "\n",
    "    x = Dense(128 * 7 * 7, activation=\"relu\")(x_noise)\n",
    "    x = Reshape((7, 7, 128))(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2D(128, kernel_size=3, padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2D(64, kernel_size=3, padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = Conv2D(1, kernel_size=3, padding=\"same\")(x)\n",
    "    gen_out = Activation(\"tanh\")(x)\n",
    "\n",
    "    return Model(x_noise, gen_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,705\n",
      "Trainable params: 856,065\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build and compile the generator\n",
    "generator = build_generator()\n",
    "generator.summary()\n",
    "generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "# The generator takes noise as input and generated imgs\n",
    "z = Input(shape=(100,))\n",
    "img = generator(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "\n",
    "        img_shape = (img_rows, img_cols, channels)\n",
    "        x_img = Input(shape=img_shape)\n",
    "\n",
    "        # first typical convlayer outputs 20x20x256 matrix\n",
    "        x = Conv2D(filters=32, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x_img)\n",
    "        \n",
    "        #\n",
    "        # capsule architecture starts from here. primarycaps coming first\n",
    "        #\n",
    "        # filters 256 (n_vectors=8 * channels=32)\n",
    "        x = Conv2D(filters=256, kernel_size=9, strides=2, padding='valid', name='conv2_primarycaps')(x)\n",
    "        # reshape into 8D vector for all 32 maps combined\n",
    "        # (primary capsule has collections of activations which denote the orientation of digit\n",
    "        # while intensity of the vector which denotes the presence of the digit)\n",
    "        x = Reshape(target_shape=[-1, 8], name='conv2_reshape')(x)\n",
    "        # the purpose is to output a number between 0 and 1 for each capsule where the length of the input decides the amount\n",
    "        x = Lambda(squash, name='squash_primarycaps')(x)\n",
    "        \n",
    "        #\n",
    "        # digitcaps are here. in this approach i'm writing a simplified version of digitcaps i.e. without tiling the input\n",
    "        # but using ordinary keras dense layers as weight holders\n",
    "        #\n",
    "        # a capsule (i) in a lower-level layer needs to decide how to send its output vector to higher-level capsules (j)\n",
    "        # it makes this decision by changing scalar weight (c_ij) that will multiply its output vector and then be treated as input to a higher-level capsule\n",
    "        #\n",
    "        # uhat = prediction vector, w = weight matrix but will act as a dense layer # ANY CORRECTIONS ARE APPRECIATED HERE, PLEASE SUBMIT PULL REQUESTS\n",
    "        # uhat (prediction vector) = u (output from a previous layer) * w\n",
    "        x = Flatten()(x)\n",
    "        # neurons 160 (num_capsules=10 * num_vectors=16)\n",
    "        x = Dense(160, kernel_initializer='he_normal', name='weights_digitcaps')(x)\n",
    "        # coupling coeff = a softmax over uhat * c (coupling coefficient) | \"the coupling coefficients between capsule (i) and all the capsules in the layer above sum to 1\"\n",
    "        # we treat the coupling coefficiant as a softmax over bias weights from the previous dense layer\n",
    "        x = Activation('softmax', name='softmax_digitcap1')(x) # softmax will make sure that each weight c_ij is a non-negative number and their sum equals to one\n",
    "        x = Dense(160, activation=squash)(x) #apply a final squashing function\n",
    "        \n",
    "        #\n",
    "        # we will repeat the routing part 2 more times (num_routing=3) to roll out the loop\n",
    "        #\n",
    "        x = Activation('softmax', name='softmax_digitcap2')(x) # softmax will make sure that each weight c_ij is a non-negative number and their sum equals to one\n",
    "        x = Dense(160, activation=squash)(x) #apply a final squashing function\n",
    "        x = Activation('softmax', name='softmax_digitcap')(x) # softmax will make sure that each weight c_ij is a non-negative number and their sum equals to one\n",
    "        x = Dense(160, activation=squash)(x) #apply a final squashing function\n",
    "    \n",
    "        pred = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        return Model(x_img, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator structure\n",
    "def build_discriminator():\n",
    "\n",
    "        img_shape = (img_rows, img_cols, channels)\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        \n",
    "        # Layer 1: Just a conventional Conv2D layer\n",
    "        conv1 = Conv2D(filters=32, kernel_size=3, strides=2, padding='same', activation='relu', name='conv1')(img)\n",
    "        # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
    "        primarycaps = PrimaryCap(conv1, dim_vector=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    "        x = Dropout(0.5)(primarycaps)\n",
    "        x = BatchNormalization(momentum=0.8)(x)\n",
    "        #digitcaps = CapsuleLayer(num_capsule=10, dim_vector=16, num_routing=3, name='digitcaps')(primarycaps)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(500, activation='relu')(x)\n",
    "        x = Dense(100, activation='relu')(x)\n",
    "        x = Dense(10, activation='relu')(x)\n",
    "        validity = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "        return Model(img, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "primarycap_conv2d (Conv2D)   (None, 3, 3, 256)         663808    \n",
      "_________________________________________________________________\n",
      "primarycap_reshape (Reshape) (None, 288, 8)            0         \n",
      "_________________________________________________________________\n",
      "primarycap_squash (Lambda)   (None, 288, 8)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 288, 8)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 288, 8)            32        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               1152500   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,867,781\n",
      "Trainable params: 1,867,765\n",
      "Non-trainable params: 16\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.summary()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the combined model we will only train the generator\n",
    "discriminator.trainable = True\n",
    "\n",
    "# The valid takes generated images as input and determines validity\n",
    "valid = discriminator(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 28, 28, 1)         856705    \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 1)                 1867781   \n",
      "=================================================================\n",
      "Total params: 2,724,486\n",
      "Trainable params: 2,723,830\n",
      "Non-trainable params: 656\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The combined model  (stacked generator and discriminator) takes\n",
    "# noise as input => generates images => determines validity \n",
    "combined = Model(z, valid)\n",
    "combined.summary()\n",
    "combined.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imgs(epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        #fig.suptitle(\"DCGAN: Generated digits\", fontsize=12)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses for further plotting\n",
    "D_L_REAL = []\n",
    "D_L_FAKE = []\n",
    "D_L = []\n",
    "D_ACC = []\n",
    "G_L = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        half_batch = int(batch_size / 2)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # Sample noise and generate a half batch of new images\n",
    "            noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "            gen_imgs = generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "            # Train the generator (wants discriminator to mistake images as real)\n",
    "            g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "            # Plot the progress\n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            D_L_REAL.append(d_loss_real)\n",
    "            D_L_FAKE.append(d_loss_fake)\n",
    "            D_L.append(d_loss)\n",
    "            D_ACC.append(d_loss[1])\n",
    "            G_L.append(g_loss)\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                save_imgs(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.741382, acc.: 28.12%] [G loss: 0.323144]\n",
      "1 [D loss: 0.378989, acc.: 50.00%] [G loss: 0.040662]\n",
      "2 [D loss: 0.455916, acc.: 50.00%] [G loss: 0.013651]\n",
      "3 [D loss: 0.540281, acc.: 50.00%] [G loss: 0.020041]\n",
      "4 [D loss: 0.585189, acc.: 50.00%] [G loss: 0.072252]\n",
      "5 [D loss: 0.662552, acc.: 50.00%] [G loss: 0.144692]\n",
      "6 [D loss: 0.792815, acc.: 50.00%] [G loss: 0.202287]\n",
      "7 [D loss: 0.896737, acc.: 50.00%] [G loss: 0.233637]\n",
      "8 [D loss: 0.965858, acc.: 50.00%] [G loss: 0.235365]\n",
      "9 [D loss: 1.109696, acc.: 50.00%] [G loss: 0.188132]\n",
      "10 [D loss: 0.951979, acc.: 50.00%] [G loss: 0.263158]\n",
      "11 [D loss: 0.841134, acc.: 50.00%] [G loss: 0.188074]\n",
      "12 [D loss: 0.599117, acc.: 59.38%] [G loss: 0.084556]\n",
      "13 [D loss: 0.709516, acc.: 59.38%] [G loss: 0.027972]\n",
      "14 [D loss: 0.673140, acc.: 65.62%] [G loss: 0.019935]\n",
      "15 [D loss: 0.985649, acc.: 53.12%] [G loss: 0.034106]\n",
      "16 [D loss: 0.815501, acc.: 46.88%] [G loss: 0.162321]\n",
      "17 [D loss: 1.110515, acc.: 46.88%] [G loss: 0.142084]\n",
      "18 [D loss: 1.526166, acc.: 50.00%] [G loss: 0.322807]\n",
      "19 [D loss: 0.943003, acc.: 50.00%] [G loss: 0.211310]\n",
      "20 [D loss: 1.585828, acc.: 50.00%] [G loss: 0.197895]\n",
      "21 [D loss: 1.604641, acc.: 50.00%] [G loss: 0.190861]\n",
      "22 [D loss: 1.397959, acc.: 50.00%] [G loss: 0.194654]\n",
      "23 [D loss: 1.445838, acc.: 50.00%] [G loss: 0.209657]\n",
      "24 [D loss: 1.301365, acc.: 50.00%] [G loss: 0.228826]\n",
      "25 [D loss: 1.256844, acc.: 50.00%] [G loss: 0.197924]\n",
      "26 [D loss: 1.375003, acc.: 50.00%] [G loss: 0.207973]\n",
      "27 [D loss: 1.234524, acc.: 50.00%] [G loss: 0.205408]\n",
      "28 [D loss: 1.248931, acc.: 50.00%] [G loss: 0.196293]\n",
      "29 [D loss: 1.262796, acc.: 50.00%] [G loss: 0.207768]\n",
      "30 [D loss: 1.220145, acc.: 50.00%] [G loss: 0.210566]\n",
      "31 [D loss: 1.173566, acc.: 50.00%] [G loss: 0.221558]\n",
      "32 [D loss: 1.143473, acc.: 50.00%] [G loss: 0.189813]\n",
      "33 [D loss: 1.186116, acc.: 50.00%] [G loss: 0.192173]\n",
      "34 [D loss: 1.153046, acc.: 50.00%] [G loss: 0.192334]\n",
      "35 [D loss: 1.096725, acc.: 50.00%] [G loss: 0.209829]\n",
      "36 [D loss: 1.143577, acc.: 50.00%] [G loss: 0.229316]\n",
      "37 [D loss: 1.114961, acc.: 50.00%] [G loss: 0.187551]\n",
      "38 [D loss: 1.172507, acc.: 50.00%] [G loss: 0.193315]\n",
      "39 [D loss: 1.166607, acc.: 50.00%] [G loss: 0.191235]\n",
      "40 [D loss: 1.219465, acc.: 50.00%] [G loss: 0.172391]\n",
      "41 [D loss: 1.159133, acc.: 50.00%] [G loss: 0.187432]\n",
      "42 [D loss: 1.098483, acc.: 50.00%] [G loss: 0.179449]\n",
      "43 [D loss: 1.118363, acc.: 50.00%] [G loss: 0.214230]\n",
      "44 [D loss: 1.189556, acc.: 50.00%] [G loss: 0.194567]\n",
      "45 [D loss: 1.100498, acc.: 50.00%] [G loss: 0.194947]\n",
      "46 [D loss: 1.154930, acc.: 50.00%] [G loss: 0.190785]\n",
      "47 [D loss: 1.157747, acc.: 50.00%] [G loss: 0.185035]\n",
      "48 [D loss: 1.181750, acc.: 50.00%] [G loss: 0.173697]\n",
      "49 [D loss: 1.205035, acc.: 50.00%] [G loss: 0.176377]\n",
      "50 [D loss: 1.096674, acc.: 50.00%] [G loss: 0.199479]\n",
      "51 [D loss: 1.081580, acc.: 50.00%] [G loss: 0.186411]\n",
      "52 [D loss: 1.163878, acc.: 50.00%] [G loss: 0.170970]\n",
      "53 [D loss: 1.068171, acc.: 50.00%] [G loss: 0.170659]\n",
      "54 [D loss: 1.043302, acc.: 50.00%] [G loss: 0.174359]\n",
      "55 [D loss: 1.150437, acc.: 50.00%] [G loss: 0.171134]\n",
      "56 [D loss: 1.145306, acc.: 50.00%] [G loss: 0.182025]\n",
      "57 [D loss: 1.126208, acc.: 50.00%] [G loss: 0.186809]\n",
      "58 [D loss: 1.161403, acc.: 50.00%] [G loss: 0.175351]\n",
      "59 [D loss: 1.213975, acc.: 50.00%] [G loss: 0.165827]\n",
      "60 [D loss: 1.206450, acc.: 50.00%] [G loss: 0.155003]\n",
      "61 [D loss: 1.195246, acc.: 50.00%] [G loss: 0.167540]\n",
      "62 [D loss: 1.143297, acc.: 50.00%] [G loss: 0.167464]\n",
      "63 [D loss: 1.213152, acc.: 50.00%] [G loss: 0.186413]\n",
      "64 [D loss: 1.196030, acc.: 50.00%] [G loss: 0.176800]\n",
      "65 [D loss: 1.098866, acc.: 50.00%] [G loss: 0.172623]\n",
      "66 [D loss: 1.098774, acc.: 50.00%] [G loss: 0.163548]\n",
      "67 [D loss: 1.116196, acc.: 50.00%] [G loss: 0.149761]\n",
      "68 [D loss: 1.279276, acc.: 50.00%] [G loss: 0.155583]\n",
      "69 [D loss: 1.200204, acc.: 50.00%] [G loss: 0.158613]\n",
      "70 [D loss: 1.136585, acc.: 50.00%] [G loss: 0.171876]\n",
      "71 [D loss: 1.094627, acc.: 50.00%] [G loss: 0.170245]\n",
      "72 [D loss: 1.145154, acc.: 50.00%] [G loss: 0.169763]\n",
      "73 [D loss: 1.261875, acc.: 50.00%] [G loss: 0.169402]\n",
      "74 [D loss: 1.194154, acc.: 50.00%] [G loss: 0.161726]\n",
      "75 [D loss: 1.127706, acc.: 50.00%] [G loss: 0.159080]\n",
      "76 [D loss: 1.169451, acc.: 50.00%] [G loss: 0.154421]\n",
      "77 [D loss: 1.187040, acc.: 50.00%] [G loss: 0.150390]\n",
      "78 [D loss: 1.189660, acc.: 50.00%] [G loss: 0.145623]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-7b7152c0720e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-2f6907a69be7>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epochs, batch_size, save_interval)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m# Train the discriminator (real classified as ones and generated as zeros)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0md_loss_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhalf_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0md_loss_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhalf_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0md_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_loss_real\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\capsule-gans\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1837\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1839\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1840\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\capsule-gans\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2357\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\capsule-gans\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\capsule-gans\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\capsule-gans\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\capsule-gans\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\capsule-gans\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(epochs=30000, batch_size=32, save_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(D_L)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (blue), Accuracy(orange)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
